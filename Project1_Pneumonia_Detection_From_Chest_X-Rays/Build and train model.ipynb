{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton Code\n",
    "\n",
    "The code below provides a skeleton for the model building & training component of your project. You can add/remove/build on code however you see fit, this is meant as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "##Import any other stats/DL/ML packages you may need here. E.g. Keras, scikit-learn, etc.\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.model_selection as skl\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, f1_score, average_precision_score\n",
    "from random import sample\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "#import tensorflow as tf\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth=True\n",
    "#sess = tf.Session(config=config)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import DenseNet121\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some early processing of your metadata for easier model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Below is some helper code to read all of your full image filepaths into a dataframe for easier manipulation\n",
    "## Load the NIH data to all_xray_df\n",
    "all_xray_df = pd.read_csv('../../data/pneumonia_data/Data_Entry_2017.csv')\n",
    "all_image_paths = {os.path.basename(x): x for x in \n",
    "                   glob(os.path.join('../../data/pneumonia_data','images*', '*', '*.png'))}\n",
    "print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n",
    "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n",
    "all_xray_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here you may want to create some extra columns in your table with binary indicators of certain diseases \n",
    "## rather than working directly with the 'Finding Labels' column\n",
    "all_xray_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_xray_labels = [x for x in all_xray_labels if len(x)>0]\n",
    "print(\"Number of labels: {}\\nLabels: {}\".format(len(all_xray_labels),\", \".join(all_xray_labels)))\n",
    "\n",
    "for label in all_xray_labels:\n",
    "    if len(label)>1: # leave out empty labels\n",
    "        all_xray_df[label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if label in finding else 0)\n",
    "\n",
    "all_xray_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we can create a new column called 'pneumonia_class' that will allow us to look at \n",
    "## images with or without pneumonia for binary classification\n",
    "all_xray_df[\"pneumonia_class\"] = all_xray_df[\"Pneumonia\"].map(lambda pneumonia: \"yes\" if pneumonia == 1.0 else \"no\")\n",
    "all_xray_df[\"pneumonia_class\"] = all_xray_df[\"pneumonia_class\"].astype(str)\n",
    "all_xray_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(df, test_size=0.2):\n",
    "    train_df, valid_df = train_test_split(df, test_size=test_size, stratify=df['Pneumonia'])\n",
    "    \n",
    "    p_inds = train_df[train_df.Pneumonia==1].index.tolist()\n",
    "    np_inds = train_df[train_df.Pneumonia==0].index.tolist()\n",
    "    np_sample = sample(np_inds,len(p_inds))\n",
    "    train_df = train_df.loc[p_inds + np_sample]\n",
    "\n",
    "\n",
    "    p_inds = valid_df[valid_df.Pneumonia==1].index.tolist()\n",
    "    np_inds = valid_df[valid_df.Pneumonia==0].index.tolist()\n",
    "    np_sample = sample(np_inds,3*len(p_inds))\n",
    "    valid_df = valid_df.loc[p_inds + np_sample]\n",
    "\n",
    "    return train_df, valid_df\n",
    "\n",
    "train_df, valid_df = create_splits(all_xray_df)\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check class balance for training set\n",
    "print('Number of pneumonia cases: {}'.format(len(train_df[train_df.Pneumonia==1.0])))\n",
    "print('Number of non-pneumonia cases: {}'.format(len(train_df[train_df.Pneumonia==0.0])))\n",
    "print('Percentage of pneumonia cases in train set {:0.4f}'.format(train_df['Pneumonia'].sum()/len(train_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check class balance for validation set\n",
    "print('Number of pneumonia cases: {}'.format(len(valid_df[valid_df.Pneumonia==1.0])))\n",
    "print('Number of non-pneumonia cases: {}'.format(len(valid_df[valid_df.Pneumonia==0.0])))\n",
    "print('Percentage of pneumonia cases in valid set {:0.4f}'.format(valid_df['Pneumonia'].sum()/len(valid_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can begin our model-building & training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First suggestion: perform some image augmentation on your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentation(rescale_only = False):\n",
    "    # for validation data\n",
    "    if rescale_only:\n",
    "        idg = ImageDataGenerator(rescale=1. / 255.0)\n",
    "    \n",
    "    # for training data\n",
    "    else:\n",
    "        idg = ImageDataGenerator(rescale=1. / 255.0,\n",
    "                                  horizontal_flip = True, \n",
    "                                  vertical_flip = False, \n",
    "                                  height_shift_range= 0.1, \n",
    "                                  width_shift_range=0.1, \n",
    "                                  rotation_range=20, \n",
    "                                  shear_range = 0.1,\n",
    "                                  zoom_range=0.1)\n",
    "    return idg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_gen(idg, train_df, x_col='path', y_col='pneumonia_class', target_size=(224, 224), batch_size=32):\n",
    "    \n",
    "    ## Create the actual generators using the output of image_augmentation for our training data\n",
    "        \n",
    "    train_gen = idg.flow_from_dataframe(dataframe=train_df, \n",
    "                                         directory=None, \n",
    "                                         x_col = x_col,\n",
    "                                         y_col = y_col,\n",
    "                                         class_mode = 'binary',\n",
    "                                         target_size = target_size, \n",
    "                                         batch_size = batch_size\n",
    "                                         )\n",
    "\n",
    "    return train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_val_gen(idg, val_df, x_col='path', y_col='pneumonia_class', target_size=(224, 224), batch_size=512):\n",
    "    \n",
    "    val_gen = idg.flow_from_dataframe(dataframe=val_df, \n",
    "                                             directory=None, \n",
    "                                             x_col = x_col,\n",
    "                                             y_col = y_col,\n",
    "                                             class_mode = 'binary',\n",
    "                                             target_size = target_size, \n",
    "                                             batch_size = batch_size\n",
    "                                             )\n",
    "    return val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idg = image_augmentation()\n",
    "train_gen = make_train_gen(train_idg, train_df)\n",
    "\n",
    "val_idg = image_augmentation(rescale_only=True)\n",
    "val_gen = make_val_gen(val_idg, valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## May want to pull a single large batch of random validation data for testing after each epoch:\n",
    "valX, valY = val_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## May want to look at some examples of our augmented training data. \n",
    "## This is helpful for understanding the extent to which data is being manipulated prior to training, \n",
    "## and can be compared with how the raw data look prior to augmentation\n",
    "\n",
    "t_x, t_y = next(train_gen)\n",
    "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n",
    "    if c_y == 1: \n",
    "        c_ax.set_title('Pneumonia')\n",
    "    else:\n",
    "        c_ax.set_title('No Pneumonia')\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your model: \n",
    "\n",
    "Recommendation here to use a pre-trained network downloaded from Keras for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(include_top=False,\n",
    "                             weights='imagenet',\n",
    "                             input_shape=(224, 224, 3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model():\n",
    "\n",
    "    model = VGG16(include_top=True, weights='imagenet')\n",
    "    transfer_layer = model.get_layer('block5_pool')\n",
    "    vgg_model = Model(inputs=model.input, outputs=transfer_layer.output)\n",
    "    for layer in vgg_model.layers[0:17]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return vgg_model\n",
    "\n",
    "vgg_model = load_pretrained_model()\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dropout(rate= 0.25))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dropout(rate = 0.25))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    return model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model.json\"\n",
    "weight_path = \"{}_model.best.hdf5\".format('xray_class')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, \n",
    "                             monitor= 'val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='auto', \n",
    "                             save_weights_only = True)\n",
    "\n",
    "early = EarlyStopping(monitor= 'val_loss', \n",
    "                      mode= 'auto', \n",
    "                      patience=10)\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 1e-4\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "callbacks_list = [checkpoint, early, LearningRateScheduler(step_decay, verbose=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "n_points = len(train_df)\n",
    "print(n_points)\n",
    "batch_size = 64\n",
    "\n",
    "steps_per_epoch = ceil(n_points / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-4) \n",
    "loss = 'binary_crossentropy'\n",
    "metrics = ['binary_accuracy']\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "history = model.fit_generator(train_gen, \n",
    "                          validation_data = (valX, valY), \n",
    "                          epochs = 40, \n",
    "                          steps_per_epoch = steps_per_epoch,\n",
    "                          callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After training for some time, look at the performance of your model by plotting some performance statistics:\n",
    "\n",
    "Note, these figures will come in handy for your FDA documentation later in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After training, make some predictions to assess your model's overall performance\n",
    "## Note that detecting pneumonia is hard even for trained expert radiologists, \n",
    "## so there is no need to make the model perfect.\n",
    "model.load_weights(weight_path)\n",
    "pred_Y = model.predict(valX, batch_size = 32, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc(t_y, p_y):\n",
    "    fpr, tpr, _ = roc_curve(t_y, p_y)\n",
    "    auc = roc_auc_score(t_y, p_y)\n",
    "    \n",
    "    plt.plot(fpr, tpr, label='Pneumonia (AUC: {:.3f})'.format(auc))\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.title(\"AUC Curve\")\n",
    "    plt.legend(['Pneumonia (AUC: {:.3f})'.format(auc)], loc='lower right')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "plot_auc(valY, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    N = len(history.history[\"loss\"])\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), history.history[\"binary_accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), history.history[\"val_binary_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you feel you are done training, you'll need to decide the proper classification threshold that optimizes your model's performance for a given metric (e.g. accuracy, F1, precision, etc.  You decide) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr(t_y, p_y):\n",
    "    fig, c_ax = plt.subplots(1,1)\n",
    "    precision, recall, thresholds = precision_recall_curve(t_y, p_y)\n",
    "    c_ax.plot(precision, recall, label = '%s (Avr Precision Score:%0.2f)'  % ('Pneumonia', average_precision_score(t_y,p_y)))\n",
    "    c_ax.legend()\n",
    "    c_ax.set_xlabel('Precision')\n",
    "    c_ax.set_ylabel('Recall')\n",
    "\n",
    "    return precision, recall, thresholds\n",
    "    \n",
    "\n",
    "precision, recall, thresholds = plot_pr(valY, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.array(precision)\n",
    "recall = np.array(recall)\n",
    "f1_score = 2 * (precision*recall)/(precision+recall)\n",
    "\n",
    "def plot_score_thresholds(precision, recall, f1_score, thresholds):\n",
    "    plt.plot(thresholds, precision, label='Precision')\n",
    "    plt.plot(thresholds, recall, label ='Recall')\n",
    "    plt.plot(thresholds, f1_score, label = 'F1 score')\n",
    "    plt.xlabel('Thresholds')\n",
    "    plt.ylabel('Precision / Recall / F1')\n",
    "    plt.title(\"Precision / Recall / F1 and Thresholds\")\n",
    "    plt.legend(['Precision', 'Recall', 'F1 score'], loc='upper right')\n",
    "    plt.show()\n",
    "plot_score_thresholds(precision[:-1], recall[:-1], f1_score[:-1], thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max F1 score: {}\".format(max(f1_score)))\n",
    "\n",
    "def calc_f1(t_y, p_y):\n",
    "    prec, recall, thresholds = precision_recall_curve(t_y, p_y)\n",
    "    return 2*(prec*recall)/(prec+recall), prec, recall, thresholds\n",
    "\n",
    "f1, prec, recall, thresholds = calc_f1(valY, pred_Y)\n",
    "\n",
    "metric_df = pd.DataFrame({'f1':f1[:-1], 'prec':prec[:-1], 'recall':recall[:-1], 'thresholds':thresholds})\n",
    "\n",
    "threshold = metric_df.iloc[metric_df['f1'].idxmax()]['thresholds']\n",
    "print('threshold corresponding to max f1:', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testY = val_gen.next()\n",
    "\n",
    "fig, m_axs = plt.subplots(10, 10, figsize = (16, 16))\n",
    "i = 0\n",
    "for (c_x, c_y, c_ax) in zip(testX[0:100], testY[0:100], m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n",
    "    if c_y == 1: \n",
    "        if pred_Y[i] > threshold:\n",
    "            c_ax.set_title('1, 1')\n",
    "        else:\n",
    "            c_ax.set_title('1, 0')\n",
    "    else:\n",
    "        if pred_Y[i] > threshold: \n",
    "            c_ax.set_title('0, 1')\n",
    "        else:\n",
    "            c_ax.set_title('0, 0')\n",
    "    c_ax.axis('off')\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just save model architecture to a .json:\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
